{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c8984e0-0792-4cf8-b3c6-446b45b717f2",
   "metadata": {},
   "source": [
    "# Embedding models\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/etna-team/etna/master?filepath=examples/210-embedding_models.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e7669f-de54-4df8-86ba-aa72c6d5fb55",
   "metadata": {},
   "source": [
    "This notebooks contains examples with embedding models.\n",
    "\n",
    "**Table of contents**\n",
    "\n",
    "* [Using embedding models directly](#chapter1)  \n",
    "* [Using embedding models with transforms](#chapter2)\n",
    "    * [Baseline](#section_3_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f73049ba-356e-4a27-a861-deeac60d006f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: git+https://github.com/etna-team/etna.git@embeddings-notebook#egg=etna[all] contains an egg fragment with a non-PEP 508 name pip 25.0 will enforce this behaviour change. A possible replacement is to use the req @ url syntax, and remove the egg fragment. Discussion can be found at https://github.com/pypa/pip/issues/11617\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/simple\n",
      "Obtaining etna[all] from git+https://github.com/etna-team/etna.git@embeddings-notebook#egg=etna[all] (from etna[all])\n",
      "  Updating ./src/etna clone (to revision embeddings-notebook)\n",
      "  Running command git fetch -q --tags\n",
      "  Running command git reset --hard -q e838d6b9aa5afd2751ca258d1450c185dcc984f3\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting Bottleneck<2.0.0,>=1.3.4 (from etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/bottleneck/1.3.8/Bottleneck-1.3.8-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (355 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m355.3/355.3 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting Deprecated==1.2.13 (from etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/deprecated/1.2.13/Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting boto3<2.0,>=1.5 (from etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/boto3/1.34.88/boto3-1.34.88-py3-none-any.whl (139 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting botocore (from etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/botocore/1.34.88/botocore-1.34.88-py3-none-any.whl (12.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m134.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting catboost>=0.21 (from etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/catboost/1.2.5/catboost-1.2.5-cp38-cp38-manylinux2014_x86_64.whl (98.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: dill<0.4.0,>=0.3.4 in /opt/conda/lib/python3.8/site-packages (from etna[all]->etna[all]) (0.3.8)\n",
      "Collecting holidays<1.0,>=0.13 (from etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/holidays/0.47/holidays-0.47-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m129.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting hydra-slayer<0.3.0,>=0.2.0 (from etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/hydra-slayer/0.2.0/hydra_slayer-0.2.0-py3-none-any.whl (12 kB)\n",
      "Collecting joblib (from etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/joblib/1.4.0/joblib-1.4.0-py3-none-any.whl (301 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.2/301.2 kB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting loguru<0.6.0,>=0.5.3 (from etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/loguru/0.5.3/loguru-0.5.3-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /opt/conda/lib/python3.8/site-packages (from etna[all]->etna[all]) (3.7.5)\n",
      "Collecting numba>=0.53.1 (from etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/numba/0.58.1/numba-0.58.1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m152.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from etna[all]->etna[all]) (1.24.4)\n",
      "Collecting omegaconf<3.0.0,>=2.1.1 (from etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/omegaconf/2.3.0/omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pandas<2.0,>=1.1 (from etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/pandas/1.5.3/pandas-1.5.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m153.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: plotly in /opt/conda/lib/python3.8/site-packages (from etna[all]->etna[all]) (5.15.0)\n",
      "Collecting pmdarima>=1.8.0 (from etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/pmdarima/2.0.4/pmdarima-2.0.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m147.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ruptures<2.0.0,>=1.1.5 (from etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/ruptures/1.1.9/ruptures-1.1.9-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m140.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scikit-learn<2,>=0.24 (from etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/scikit-learn/1.3.2/scikit_learn-1.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m152.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting scipy<2.0,>=1.0 (from etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/scipy/1.10.1/scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting seaborn<0.12.0,>=0.11.1 (from etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/seaborn/0.11.2/seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.8/292.8 kB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting statsmodels<0.14,>=0.12 (from etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/statsmodels/0.13.5/statsmodels-0.13.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m149.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tbats<2.0.0,>=1.1.0 (from etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/tbats/1.1.3/tbats-1.1.3-py3-none-any.whl (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting toml<0.11.0,>=0.10.2 (from etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/toml/0.10.2/toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting typer<0.5.0,>=0.4.0 (from etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/typer/0.4.2/typer-0.4.2-py3-none-any.whl (27 kB)\n",
      "Collecting types-Deprecated==1.2.9 (from etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/types-deprecated/1.2.9/types_Deprecated-1.2.9-py3-none-any.whl (3.2 kB)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.8/site-packages (from etna[all]->etna[all]) (4.4.0)\n",
      "Collecting wrapt<2,>=1.10 (from Deprecated==1.2.13->etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/wrapt/1.16.0/wrapt-1.16.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.4/83.4 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting einops (from etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/einops/0.7.0/einops-0.7.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting optuna<3.0.0,>=2.5.0 (from etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/optuna/2.10.1/optuna-2.10.1-py3-none-any.whl (308 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.2/308.2 kB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting prophet<2.0,>=1.0 (from etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/prophet/1.1.5/prophet-1.1.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.4/14.4 MB\u001b[0m \u001b[31m117.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pytorch-forecasting<0.10.0,>=0.9.0 (from etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/pytorch-forecasting/0.9.2/pytorch_forecasting-0.9.2-py3-none-any.whl (113 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.4/113.4 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pytorch-lightning (from etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/pytorch-lightning/2.2.2/pytorch_lightning-2.2.2-py3-none-any.whl (801 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m801.9/801.9 kB\u001b[0m \u001b[31m125.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyts<0.13.0,>=0.12.0 (from etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/pyts/0.12.0/pyts-0.12.0-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m136.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sqlalchemy<2.0.0,>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from etna[all]->etna[all]) (1.4.41)\n",
      "Collecting statsforecast==1.4 (from etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/statsforecast/1.4.0/statsforecast-1.4.0-py3-none-any.whl (91 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torch<3,>=1.8.0 (from etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/torch/2.2.2/torch-2.2.2-cp38-cp38-manylinux1_x86_64.whl (755.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tsfresh<0.21.0,>=0.20.0 (from etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/tsfresh/0.20.2/tsfresh-0.20.2-py2.py3-none-any.whl (95 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.8/95.8 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting wandb<0.13.0,>=0.12.2 (from etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/wandb/0.12.21/wandb-0.12.21-py2.py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m104.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from statsforecast==1.4->etna[all]->etna[all]) (4.66.2)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0,>=1.5->etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/jmespath/1.0.1/jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2.0,>=1.5->etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/s3transfer/0.10.1/s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.8/site-packages (from botocore->etna[all]->etna[all]) (2.8.2)\n",
      "Collecting urllib3<1.27,>=1.25.4 (from botocore->etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/urllib3/1.26.18/urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting graphviz (from catboost>=0.21->etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/graphviz/0.20.3/graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from catboost>=0.21->etna[all]->etna[all]) (1.16.0)\n",
      "Collecting llvmlite<0.42,>=0.41.0dev0 (from numba>=0.53.1->etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/llvmlite/0.41.1/llvmlite-0.41.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.8/site-packages (from numba>=0.53.1->etna[all]->etna[all]) (7.1.0)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<3.0.0,>=2.1.1->etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/antlr4-python3-runtime/4.9.3/antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.1.0 in /opt/conda/lib/python3.8/site-packages (from omegaconf<3.0.0,>=2.1.1->etna[all]->etna[all]) (6.0.1)\n",
      "Requirement already satisfied: alembic in /opt/conda/lib/python3.8/site-packages (from optuna<3.0.0,>=2.5.0->etna[all]->etna[all]) (1.8.1)\n",
      "Collecting cliff (from optuna<3.0.0,>=2.5.0->etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/cliff/4.6.0/cliff-4.6.0-py3-none-any.whl (81 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.1/81.1 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cmaes>=0.8.2 (from optuna<3.0.0,>=2.5.0->etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/cmaes/0.10.0/cmaes-0.10.0-py3-none-any.whl (29 kB)\n",
      "Collecting colorlog (from optuna<3.0.0,>=2.5.0->etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/colorlog/6.8.2/colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from optuna<3.0.0,>=2.5.0->etna[all]->etna[all]) (24.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas<2.0,>=1.1->etna[all]->etna[all]) (2022.4)\n",
      "Collecting Cython!=0.29.18,!=0.29.31,>=0.29 (from pmdarima>=1.8.0->etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/cython/3.0.10/Cython-3.0.10-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m147.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /opt/conda/lib/python3.8/site-packages (from pmdarima>=1.8.0->etna[all]->etna[all]) (65.4.1)\n",
      "Collecting cmdstanpy>=1.0.4 (from prophet<2.0,>=1.0->etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/cmdstanpy/1.2.2/cmdstanpy-1.2.2-py3-none-any.whl (94 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.4/94.4 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: importlib-resources in /opt/conda/lib/python3.8/site-packages (from prophet<2.0,>=1.0->etna[all]->etna[all]) (5.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->etna[all]->etna[all]) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib->etna[all]->etna[all]) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->etna[all]->etna[all]) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->etna[all]->etna[all]) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->etna[all]->etna[all]) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->etna[all]->etna[all]) (3.0.9)\n",
      "Collecting pytorch-lightning (from etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/pytorch-lightning/1.9.5/pytorch_lightning-1.9.5-py3-none-any.whl (829 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.5/829.5 kB\u001b[0m \u001b[31m128.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scikit-learn<2,>=0.24 (from etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/scikit-learn/1.0.2/scikit_learn-1.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m105.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch<3,>=1.8.0 (from etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/torch/1.13.1/torch-1.13.1-cp38-cp38-manylinux1_x86_64.whl (887.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.4/887.4 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting fsspec>2021.06.0 (from fsspec[http]>2021.06.0->pytorch-lightning->etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/fsspec/2024.3.1/fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torchmetrics>=0.7.0 (from pytorch-lightning->etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/torchmetrics/1.3.2/torchmetrics-1.3.2-py3-none-any.whl (841 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.5/841.5 kB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting lightning-utilities>=0.6.0.post0 (from pytorch-lightning->etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/lightning-utilities/0.11.2/lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn<2,>=0.24->etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/threadpoolctl/3.4.0/threadpoolctl-3.4.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.8/site-packages (from sqlalchemy<2.0.0,>=1.1.0->etna[all]->etna[all]) (1.1.3)\n",
      "Collecting patsy>=0.5.2 (from statsmodels<0.14,>=0.12->etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/patsy/0.5.6/patsy-0.5.6-py2.py3-none-any.whl (233 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.9/233.9 kB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch<3,>=1.8.0->etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/nvidia-cuda-runtime-cu11/11.7.99/nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch<3,>=1.8.0->etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/nvidia-cudnn-cu11/8.5.0.96/nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch<3,>=1.8.0->etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/nvidia-cublas-cu11/11.10.3.66/nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch<3,>=1.8.0->etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/nvidia-cuda-nvrtc-cu11/11.7.99/nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m119.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel in /opt/conda/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch<3,>=1.8.0->etna[all]->etna[all]) (0.37.1)\n",
      "Requirement already satisfied: requests>=2.9.1 in /opt/conda/lib/python3.8/site-packages (from tsfresh<0.21.0,>=0.20.0->etna[all]->etna[all]) (2.31.0)\n",
      "Collecting stumpy>=1.7.2 (from tsfresh<0.21.0,>=0.20.0->etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/stumpy/1.12.0/stumpy-1.12.0-py3-none-any.whl (169 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.1/169.1 kB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cloudpickle (from tsfresh<0.21.0,>=0.20.0->etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/cloudpickle/3.0.0/cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.8/site-packages (from typer<0.5.0,>=0.4.0->etna[all]->etna[all]) (8.1.7)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb<0.13.0,>=0.12.2->etna[all]->etna[all]) (3.1.43)\n",
      "Collecting promise<3,>=2.0 (from wandb<0.13.0,>=0.12.2->etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/promise/2.3/promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting shortuuid>=0.5.0 (from wandb<0.13.0,>=0.12.2->etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/shortuuid/1.0.13/shortuuid-1.0.13-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb<0.13.0,>=0.12.2->etna[all]->etna[all]) (5.9.2)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb<0.13.0,>=0.12.2->etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/sentry-sdk/1.45.0/sentry_sdk-1.45.0-py2.py3-none-any.whl (267 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.1/267.1 kB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb<0.13.0,>=0.12.2->etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/docker-pycreds/0.4.0/docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting protobuf<4.0dev,>=3.12.0 (from wandb<0.13.0,>=0.12.2->etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/protobuf/3.20.3/protobuf-3.20.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pathtools (from wandb<0.13.0,>=0.12.2->etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/pathtools/0.1.2/pathtools-0.1.2.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting setproctitle (from wandb<0.13.0,>=0.12.2->etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/setproctitle/1.3.3/setproctitle-1.3.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from plotly->etna[all]->etna[all]) (8.2.3)\n",
      "Collecting stanio<2.0.0,>=0.4.0 (from cmdstanpy>=1.0.4->prophet<2.0,>=1.0->etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/stanio/0.5.0/stanio-0.5.0-py3-none-any.whl (8.0 kB)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.8/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning->etna[all]->etna[all]) (3.9.5)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.8/site-packages (from GitPython>=1.0.0->wandb<0.13.0,>=0.12.2->etna[all]->etna[all]) (4.0.11)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from importlib-resources->prophet<2.0,>=1.0->etna[all]->etna[all]) (3.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests>=2.9.1->tsfresh<0.21.0,>=0.20.0->etna[all]->etna[all]) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.9.1->tsfresh<0.21.0,>=0.20.0->etna[all]->etna[all]) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.9.1->tsfresh<0.21.0,>=0.20.0->etna[all]->etna[all]) (2022.9.24)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.8/site-packages (from alembic->optuna<3.0.0,>=2.5.0->etna[all]->etna[all]) (1.2.3)\n",
      "Collecting PrettyTable>=0.7.2 (from cliff->optuna<3.0.0,>=2.5.0->etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/prettytable/3.10.0/prettytable-3.10.0-py3-none-any.whl (28 kB)\n",
      "Collecting autopage>=0.4.0 (from cliff->optuna<3.0.0,>=2.5.0->etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/autopage/0.5.2/autopage-0.5.2-py3-none-any.whl (30 kB)\n",
      "Collecting cmd2>=1.0.0 (from cliff->optuna<3.0.0,>=2.5.0->etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/cmd2/2.4.3/cmd2-2.4.3-py3-none-any.whl (147 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.2/147.2 kB\u001b[0m \u001b[31m470.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting stevedore>=2.0.1 (from cliff->optuna<3.0.0,>=2.5.0->etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/stevedore/5.2.0/stevedore-5.2.0-py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m170.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->etna[all]->etna[all]) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->etna[all]->etna[all]) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->etna[all]->etna[all]) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->etna[all]->etna[all]) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->etna[all]->etna[all]) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->etna[all]->etna[all]) (4.0.3)\n",
      "Collecting pyperclip>=1.6 (from cmd2>=1.0.0->cliff->optuna<3.0.0,>=2.5.0->etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/pyperclip/1.8.2/pyperclip-1.8.2.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: wcwidth>=0.1.7 in /opt/conda/lib/python3.8/site-packages (from cmd2>=1.0.0->cliff->optuna<3.0.0,>=2.5.0->etna[all]->etna[all]) (0.2.5)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb<0.13.0,>=0.12.2->etna[all]->etna[all]) (5.0.1)\n",
      "Collecting pbr!=2.1.0,>=2.0.0 (from stevedore>=2.0.1->cliff->optuna<3.0.0,>=2.5.0->etna[all]->etna[all])\n",
      "  Downloading https://artifactory.tcsbank.ru/artifactory/api/pypi/python-all/packages/packages/pbr/6.0.0/pbr-6.0.0-py2.py3-none-any.whl (107 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.5/107.5 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.8/site-packages (from Mako->alembic->optuna<3.0.0,>=2.5.0->etna[all]->etna[all]) (2.1.1)\n",
      "Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: etna, antlr4-python3-runtime, promise, pathtools, pyperclip\n",
      "  Building editable for etna (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for etna: filename=etna-2.6.0-py3-none-any.whl size=11532 sha256=699e5c816620f96c49fee94f1d866599a911dd75485f72245d38b7310800bc57\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-0p6a26ce/wheels/2a/ea/3b/421b719bf871e26aa6cfc96fe4bce2ccecb5785f85e6e41ce0\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=073dd41b4c0e2930055c81987873c0a18494550d28426705bac7af8106521cdb\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/93/f2/79/ef8d5b7d3ef56d11dcdde40503a17a8619d92e9c1a2f4c1009\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21486 sha256=b010cffe3c775c1f5a85af6d4d56e67c54472d1ae23a9e957236f77b26616351\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/01/ef/14/3a9c0a9887ee9eb4f6ee4f80b739a1006ea7e5387f76eef81b\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8792 sha256=c6fcf29439eea82390339d228d7668d98f09e97d286e8c4fac3d0ca2731b9d99\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/11/95/55/fd4a67315075d9975caf36f34afb0cff24c56793161939ed92\n",
      "  Building wheel for pyperclip (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11123 sha256=e5879303e1cc22d35d41fea3bd0314f1f807adf574ba095de5e7ee1ad06c82c8\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/0e/55/ea/f3883dd88f84795337472d85488ce594a41ce5fc8685474e73\n",
      "Successfully built etna antlr4-python3-runtime promise pathtools pyperclip\n",
      "Installing collected packages: types-Deprecated, pyperclip, pathtools, antlr4-python3-runtime, wrapt, urllib3, typer, toml, threadpoolctl, stanio, shortuuid, setproctitle, scipy, protobuf, promise, PrettyTable, pbr, patsy, omegaconf, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, loguru, llvmlite, lightning-utilities, joblib, jmespath, hydra-slayer, graphviz, fsspec, einops, docker-pycreds, Cython, colorlog, cmd2, cmaes, cloudpickle, Bottleneck, autopage, stevedore, sentry-sdk, scikit-learn, ruptures, pandas, nvidia-cudnn-cu11, numba, holidays, Deprecated, botocore, wandb, torch, stumpy, statsmodels, seaborn, s3transfer, pyts, cmdstanpy, cliff, catboost, tsfresh, torchmetrics, statsforecast, prophet, pmdarima, optuna, boto3, tbats, pytorch-lightning, pytorch-forecasting, etna\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.1\n",
      "    Uninstalling urllib3-2.2.1:\n",
      "      Successfully uninstalled urllib3-2.2.1\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.3\n",
      "    Uninstalling protobuf-4.25.3:\n",
      "      Successfully uninstalled protobuf-4.25.3\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.0.3\n",
      "    Uninstalling pandas-2.0.3:\n",
      "      Successfully uninstalled pandas-2.0.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ml-core-python-sdk 0.2.42 requires protobuf<5.0.0,>=4.21.5, but you have protobuf 3.20.3 which is incompatible.\n",
      "types-requests 2.31.0.20240406 requires urllib3>=2, but you have urllib3 1.26.18 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Bottleneck-1.3.8 Cython-3.0.10 Deprecated-1.2.13 PrettyTable-3.10.0 antlr4-python3-runtime-4.9.3 autopage-0.5.2 boto3-1.34.88 botocore-1.34.88 catboost-1.2.5 cliff-4.6.0 cloudpickle-3.0.0 cmaes-0.10.0 cmd2-2.4.3 cmdstanpy-1.2.2 colorlog-6.8.2 docker-pycreds-0.4.0 einops-0.7.0 etna-2.6.0 fsspec-2024.3.1 graphviz-0.20.3 holidays-0.47 hydra-slayer-0.2.0 jmespath-1.0.1 joblib-1.4.0 lightning-utilities-0.11.2 llvmlite-0.41.1 loguru-0.5.3 numba-0.58.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 omegaconf-2.3.0 optuna-2.10.1 pandas-1.5.3 pathtools-0.1.2 patsy-0.5.6 pbr-6.0.0 pmdarima-2.0.4 promise-2.3 prophet-1.1.5 protobuf-3.20.3 pyperclip-1.8.2 pytorch-forecasting-0.9.2 pytorch-lightning-1.9.5 pyts-0.12.0 ruptures-1.1.9 s3transfer-0.10.1 scikit-learn-1.0.2 scipy-1.10.1 seaborn-0.11.2 sentry-sdk-1.45.0 setproctitle-1.3.3 shortuuid-1.0.13 stanio-0.5.0 statsforecast-1.4.0 statsmodels-0.13.5 stevedore-5.2.0 stumpy-1.12.0 tbats-1.1.3 threadpoolctl-3.4.0 toml-0.10.2 torch-1.13.1 torchmetrics-1.3.2 tsfresh-0.20.2 typer-0.4.2 types-Deprecated-1.2.9 urllib3-1.26.18 wandb-0.12.21 wrapt-1.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -e git+https://github.com/etna-team/etna.git@embeddings-notebook#egg=etna[all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf32c6a9-f920-4888-ac9d-f4a1c454cd91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Disabling SSL verification.  Connections to this server are not verified and may be insecure!\n"
     ]
    }
   ],
   "source": [
    "from etna.transforms.embeddings.models import TS2VecEmbeddingModel, TSTCCEmbeddingModel\n",
    "from etna.transforms.embeddings.models import BaseEmbeddingModel\n",
    "from etna.datasets import TSDataset, generate_ar_df\n",
    "from etna.transforms import EmbeddingSegmentTransform, EmbeddingWindowTransform, FilterFeaturesTransform\n",
    "from etna.pipeline import Pipeline\n",
    "from etna.models import CatBoostMultiSegmentModel, LinearMultiSegmentModel\n",
    "from etna.transforms import LagTransform\n",
    "from etna.metrics import SMAPE\n",
    "from etna.datasets import load_dataset\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d732e5b1-2c10-4de3-93ce-c6395ddbd4f1",
   "metadata": {},
   "source": [
    "## 1. Using embedding models directly <a class=\"anchor\" id=\"chapter1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c63da5a-eed8-472b-9786-9884a5bb78d1",
   "metadata": {},
   "source": [
    "We have two models to generate embeddings for time series: `TS2VecEmbeddingModel` and `TSTCCEmbeddingModel`.\n",
    "\n",
    "Each model has following methods:\n",
    "- `fit` to train model:\n",
    "- `encode_segment` to generate embeddings for the whole series. That features are regressors.\n",
    "- `encode_window` to generate embeddings for each timestamp. That features are not regressors and should be used as lags for future.\n",
    "- `freeze` to enable or disable skipping training in `fit` method. It is useful, for example, when you have a pretrained model and you want only to genarate embeddings without new training during `backtest`.\n",
    "- `save` and `load` to save and load pretrained models, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f99c90c5-8a8b-481a-848f-ebcb00b22bb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>segment</th>\n",
       "      <th>segment_0</th>\n",
       "      <th>segment_1</th>\n",
       "      <th>segment_2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th>target</th>\n",
       "      <th>target</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>1.624345</td>\n",
       "      <td>1.462108</td>\n",
       "      <td>-1.100619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-02</th>\n",
       "      <td>1.012589</td>\n",
       "      <td>-0.598033</td>\n",
       "      <td>0.044105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-03</th>\n",
       "      <td>0.484417</td>\n",
       "      <td>-0.920450</td>\n",
       "      <td>0.945695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-04</th>\n",
       "      <td>-0.588551</td>\n",
       "      <td>-1.304504</td>\n",
       "      <td>1.448190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-05</th>\n",
       "      <td>0.276856</td>\n",
       "      <td>-0.170735</td>\n",
       "      <td>2.349046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "segment    segment_0 segment_1 segment_2\n",
       "feature       target    target    target\n",
       "timestamp                               \n",
       "2001-01-01  1.624345  1.462108 -1.100619\n",
       "2001-01-02  1.012589 -0.598033  0.044105\n",
       "2001-01-03  0.484417 -0.920450  0.945695\n",
       "2001-01-04 -0.588551 -1.304504  1.448190\n",
       "2001-01-05  0.276856 -0.170735  2.349046"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = generate_ar_df(periods=10, start_time=\"2001-01-01\", n_segments=3)\n",
    "ts = TSDataset(df, freq=\"D\")\n",
    "ts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9712e58c-73fe-475e-807b-ae082752fcf8",
   "metadata": {},
   "source": [
    "Now let's work with models directly.\n",
    "\n",
    "They are expecting array with shapes\n",
    "(n_segments, n_timestamps, num_features). The example shows working with `TS2VecEmbeddingModel`, it is all the same with `TSTCCEmbeddingModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05a191ee-17dd-4cb1-a993-73aee7706272",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 10, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = ts.df.values.reshape(ts.size()).transpose(1, 0, 2)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0263277f-b642-4c1b-8f19-a42520d6d09e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ts2vec = TS2VecEmbeddingModel(input_dims=1, output_dims=2)\n",
    "model_ts2vec.fit(x, n_epochs=1)\n",
    "segment_embeddings = model_ts2vec.encode_segment(x)\n",
    "segment_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26329bf0-e955-46ad-9962-4ea1295ef671",
   "metadata": {},
   "source": [
    "As we are using `encode_segment` we get `output_dims` features consisting of one value for each segment.\n",
    "\n",
    "And what about `encode_window`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a307886-cdf2-4e98-9a8e-3917741f287c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 10, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_embeddings = model_ts2vec.encode_window(x)\n",
    "window_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aded40fc-382c-4f7a-901b-8498f9258c3b",
   "metadata": {},
   "source": [
    "We get `output_dims` features consisting of `n_timestamps` values for each segment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbb2210-d77f-426e-91b2-3729544ce872",
   "metadata": {},
   "source": [
    "## 2. Using embedding models with transforms <a class=\"anchor\" id=\"chapter2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459e90a9-97fb-4922-bc6a-52500b3a132e",
   "metadata": {},
   "source": [
    "In this section we will test our models on example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7827e25-4597-451a-88f8-5e0475556041",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HORIZON = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17955757-7585-4db0-889b-dbd978339822",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.1 Baseline <a class=\"anchor\" id=\"section_2_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c92c86f-fce7-442b-a7f4-0c024344bec9",
   "metadata": {},
   "source": [
    "Before working with embedding features, let's make forecasts using usual features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21ac6694-1c3c-4fdc-a96a-3d0544ee90df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>segment</th>\n",
       "      <th>M1000_MACRO</th>\n",
       "      <th>M1001_MACRO</th>\n",
       "      <th>M1002_MACRO</th>\n",
       "      <th>M1003_MACRO</th>\n",
       "      <th>M1004_MACRO</th>\n",
       "      <th>M1005_MACRO</th>\n",
       "      <th>M1006_MACRO</th>\n",
       "      <th>M1007_MACRO</th>\n",
       "      <th>M1008_MACRO</th>\n",
       "      <th>M1009_MACRO</th>\n",
       "      <th>...</th>\n",
       "      <th>M992_MACRO</th>\n",
       "      <th>M993_MACRO</th>\n",
       "      <th>M994_MACRO</th>\n",
       "      <th>M995_MACRO</th>\n",
       "      <th>M996_MACRO</th>\n",
       "      <th>M997_MACRO</th>\n",
       "      <th>M998_MACRO</th>\n",
       "      <th>M999_MACRO</th>\n",
       "      <th>M99_MICRO</th>\n",
       "      <th>M9_MICRO</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th>target</th>\n",
       "      <th>target</th>\n",
       "      <th>target</th>\n",
       "      <th>target</th>\n",
       "      <th>target</th>\n",
       "      <th>target</th>\n",
       "      <th>target</th>\n",
       "      <th>target</th>\n",
       "      <th>target</th>\n",
       "      <th>target</th>\n",
       "      <th>...</th>\n",
       "      <th>target</th>\n",
       "      <th>target</th>\n",
       "      <th>target</th>\n",
       "      <th>target</th>\n",
       "      <th>target</th>\n",
       "      <th>target</th>\n",
       "      <th>target</th>\n",
       "      <th>target</th>\n",
       "      <th>target</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1428 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "segment   M1000_MACRO M1001_MACRO M1002_MACRO M1003_MACRO M1004_MACRO  \\\n",
       "feature        target      target      target      target      target   \n",
       "timestamp                                                               \n",
       "0                 NaN         NaN         NaN         NaN         NaN   \n",
       "1                 NaN         NaN         NaN         NaN         NaN   \n",
       "2                 NaN         NaN         NaN         NaN         NaN   \n",
       "3                 NaN         NaN         NaN         NaN         NaN   \n",
       "4                 NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "segment   M1005_MACRO M1006_MACRO M1007_MACRO M1008_MACRO M1009_MACRO  ...  \\\n",
       "feature        target      target      target      target      target  ...   \n",
       "timestamp                                                              ...   \n",
       "0                 NaN         NaN         NaN         NaN         NaN  ...   \n",
       "1                 NaN         NaN         NaN         NaN         NaN  ...   \n",
       "2                 NaN         NaN         NaN         NaN         NaN  ...   \n",
       "3                 NaN         NaN         NaN         NaN         NaN  ...   \n",
       "4                 NaN         NaN         NaN         NaN         NaN  ...   \n",
       "\n",
       "segment   M992_MACRO M993_MACRO M994_MACRO M995_MACRO M996_MACRO M997_MACRO  \\\n",
       "feature       target     target     target     target     target     target   \n",
       "timestamp                                                                     \n",
       "0                NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "1                NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "2                NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "3                NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "4                NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "segment   M998_MACRO M999_MACRO M99_MICRO M9_MICRO  \n",
       "feature       target     target    target   target  \n",
       "timestamp                                           \n",
       "0                NaN        NaN       NaN      NaN  \n",
       "1                NaN        NaN       NaN      NaN  \n",
       "2                NaN        NaN       NaN      NaN  \n",
       "3                NaN        NaN       NaN      NaN  \n",
       "4                NaN        NaN       NaN      NaN  \n",
       "\n",
       "[5 rows x 1428 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = load_dataset(\"m3_monthly\")\n",
    "ts.drop_features(features=[\"origin_timestamp\"])\n",
    "ts.df_exog=None\n",
    "ts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe224f12-6b86-4513-8d61-3fa0cb895eb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=1)]: Done   2 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=1)]: Done   3 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=1)]: Done   4 tasks      | elapsed:   22.5s\n",
      "[Parallel(n_jobs=1)]: Done   5 tasks      | elapsed:   28.6s\n",
      "[Parallel(n_jobs=1)]: Done   5 tasks      | elapsed:   28.6s\n",
      "[Parallel(n_jobs=1)]: Done   1 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=1)]: Done   2 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=1)]: Done   3 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=1)]: Done   4 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=1)]: Done   5 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=1)]: Done   5 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=1)]: Done   1 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done   2 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done   3 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done   4 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done   5 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done   5 tasks      | elapsed:    0.4s\n"
     ]
    }
   ],
   "source": [
    "model = CatBoostMultiSegmentModel()\n",
    "\n",
    "lag_transform = LagTransform(in_column=\"target\", lags=list(range(HORIZON, HORIZON+6)), out_column='lag')\n",
    "\n",
    "pipeline = Pipeline(model=model, transforms=[lag_transform], horizon=HORIZON)\n",
    "metrics_df, _, _ = pipeline.backtest(ts, metrics=[SMAPE()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08f8e06b-788f-4dc0-bb56-463207592b3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMAPE:  14.862075501818936\n"
     ]
    }
   ],
   "source": [
    "print(\"SMAPE: \", metrics_df[\"SMAPE\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa358d6-c1a0-460a-b1a2-7a123b5b4eec",
   "metadata": {},
   "source": [
    "### 2.2 EmbeddingSegmentTransform <a class=\"anchor\" id=\"section_2_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7ca5fd-4186-4bf4-ac32-0bace7802ca9",
   "metadata": {},
   "source": [
    "`EmbeddingSegmentTransform` calls models' `encode_segment` method inside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f05f8f02-4d24-4438-ac15-9ed45e2e4f78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def forecast_with_segment_embeddings(\n",
    "    emb_model: BaseEmbeddingModel, training_params: dict\n",
    ") -> float:\n",
    "    model = CatBoostMultiSegmentModel(task_type=\"GPU\", devices=\"0\")\n",
    "\n",
    "    emb_transform = EmbeddingSegmentTransform(\n",
    "        in_columns=[\"target\"],\n",
    "        embedding_model=emb_model,\n",
    "        training_params=training_params,\n",
    "        out_column='emb'\n",
    "    )\n",
    "    pipeline = Pipeline(model=model, transforms=[lag_transform, emb_transform], horizon=HORIZON)\n",
    "    metrics_df, _, _ = pipeline.backtest(ts, metrics=[SMAPE()])\n",
    "    smape_score = metrics_df[\"SMAPE\"].mean()\n",
    "    return smape_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc237e1-d2e3-48ee-99b5-ac35b957717b",
   "metadata": {},
   "source": [
    "You can see training parameters of the model to pass it to transform.\n",
    "\n",
    "Let's begin with `TSTCCEmbeddingModel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e6cc297-48bd-4614-bcbe-44e5732bf3a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mTSTCCEmbeddingModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_epochs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtemperature\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlambda1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlambda2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'TSTCCEmbeddingModel'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Fit TSTCC embedding model.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "x:\n",
       "    data with shapes (n_segments, n_timestamps, input_dims).\n",
       "n_epochs:\n",
       "    The number of epochs. When this reaches, the training stops.\n",
       "lr:\n",
       "    The learning rate.\n",
       "temperature:\n",
       "    Temperature in NTXentLoss.\n",
       "lambda1:\n",
       "    The relative weight of the first item in the loss (temporal contrasting loss).\n",
       "lambda2:\n",
       "    The relative weight of the second item in the loss (contextual contrasting loss).\n",
       "verbose:\n",
       "    Whether to print the training loss after each epoch.\n",
       "\u001b[0;31mFile:\u001b[0m      /workdir/src/etna/etna/transforms/embeddings/models/tstcc.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?TSTCCEmbeddingModel.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "516b209e-7bd2-45c6-8db0-b1708ffda0fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 tasks      | elapsed:   32.6s\n",
      "[Parallel(n_jobs=1)]: Done   2 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=1)]: Done   3 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=1)]: Done   4 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=1)]: Done   5 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=1)]: Done   5 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=1)]: Done   1 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=1)]: Done   2 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=1)]: Done   3 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=1)]: Done   4 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=1)]: Done   5 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=1)]: Done   5 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=1)]: Done   1 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done   2 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done   3 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done   4 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done   5 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done   5 tasks      | elapsed:    0.3s\n"
     ]
    }
   ],
   "source": [
    "emb_model = TSTCCEmbeddingModel(\n",
    "    input_dims=1, tc_hidden_dim=128, depth=5, output_dims=16, device=\"cuda\"\n",
    ")\n",
    "training_params = {\"n_epochs\": 10}\n",
    "smape_score = forecast_with_segment_embeddings(emb_model, training_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afc11f19-a9a7-4507-b842-bd0a0b22668e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMAPE:  14.503439221629804\n"
     ]
    }
   ],
   "source": [
    "print(\"SMAPE: \", smape_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e35346-6f16-4d42-8a33-b98bf5679046",
   "metadata": {},
   "source": [
    "Better then without embeddings. Let's try `TS2VecEmbeddingModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b7e43f6-9ce3-4a3f-b6e9-70ed46b272e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 tasks      | elapsed:   23.4s\n",
      "[Parallel(n_jobs=1)]: Done   2 tasks      | elapsed:   46.8s\n",
      "[Parallel(n_jobs=1)]: Done   3 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=1)]: Done   4 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=1)]: Done   5 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=1)]: Done   5 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=1)]: Done   1 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=1)]: Done   2 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=1)]: Done   3 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=1)]: Done   4 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=1)]: Done   5 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=1)]: Done   5 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=1)]: Done   1 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done   2 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done   3 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done   4 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done   5 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done   5 tasks      | elapsed:    0.3s\n"
     ]
    }
   ],
   "source": [
    "emb_model = TS2VecEmbeddingModel(\n",
    "    input_dims=1, hidden_dims=128, depth=5, output_dims=16, device=\"cuda\"\n",
    ")\n",
    "training_params = {\"n_epochs\": 10}\n",
    "smape_score = forecast_with_segment_embeddings(emb_model, training_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3394c1e9-5290-4ab0-99c3-434454c7d656",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMAPE:  13.98802254384104\n"
     ]
    }
   ],
   "source": [
    "print(\"SMAPE: \", smape_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da58c577-3519-41a7-b63c-1da896121954",
   "metadata": {},
   "source": [
    "Much better. Now let's try another transform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949a07ba-548f-4b09-bcba-a07f76c9d501",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.3 EmbeddingWindowTransform <a class=\"anchor\" id=\"section_2_3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3ef834-fcd7-4ee1-85e9-a8ace8dde8a4",
   "metadata": {},
   "source": [
    "`EmbeddingWindowTransform` calls models' `encode_window` method inside. As we have discussed, this features are not regressors and should be used as lags for future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b39d1abe-42f9-44ff-af5e-f93d08c0ac02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def forecast_with_window_embeddings(\n",
    "    emb_model: BaseEmbeddingModel, training_params: dict\n",
    ") -> float:\n",
    "    model = CatBoostMultiSegmentModel(task_type=\"GPU\", devices=\"0\")\n",
    "\n",
    "    output_dims = emb_model.output_dims\n",
    "\n",
    "    emb_transform = EmbeddingWindowTransform(\n",
    "        in_columns=[\"target\"],\n",
    "        embedding_model=emb_model,\n",
    "        training_params=training_params,\n",
    "        out_column='embedding_window'\n",
    "    )\n",
    "    lag_emb_transforms = [\n",
    "        LagTransform(\n",
    "            in_column=f\"embedding_window_{i}\", lags=[HORIZON], out_column=f\"lag_emb_{i}\"\n",
    "        ) for i in range(output_dims)\n",
    "    ]\n",
    "    filter_transforms = FilterFeaturesTransform(\n",
    "        exclude=[f\"embedding_window_{i}\" for i in range(output_dims)]\n",
    "    )\n",
    "    \n",
    "    transforms = [lag_transform] + [emb_transform] + lag_emb_transforms + [filter_transforms]\n",
    "\n",
    "    pipeline = Pipeline(model=model, transforms=transforms, horizon=HORIZON)\n",
    "    metrics_df, _, _ = pipeline.backtest(ts, metrics=[SMAPE()])\n",
    "    smape_score = metrics_df[\"SMAPE\"].mean()\n",
    "    return smape_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e663aa0-778d-4393-80e6-7ef888210ec5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=1)]: Done   2 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=1)]: Done   3 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=1)]: Done   4 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=1)]: Done   5 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=1)]: Done   5 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=1)]: Done   1 tasks      | elapsed:   28.3s\n",
      "[Parallel(n_jobs=1)]: Done   2 tasks      | elapsed:   56.6s\n",
      "[Parallel(n_jobs=1)]: Done   3 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=1)]: Done   4 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=1)]: Done   5 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=1)]: Done   5 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=1)]: Done   1 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done   2 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done   3 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done   4 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done   5 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done   5 tasks      | elapsed:    0.3s\n"
     ]
    }
   ],
   "source": [
    "emb_model = TSTCCEmbeddingModel(\n",
    "    input_dims=1, tc_hidden_dim=64, depth=5, output_dims=16, device=\"cuda\"\n",
    ")\n",
    "training_params = {\"n_epochs\": 20, \"lr\": 0.0005}\n",
    "smape_score = forecast_with_window_embeddings(emb_model, training_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd890c55-ea57-4f51-a2e1-320cc4111b46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMAPE:  105.1297881443976\n"
     ]
    }
   ],
   "source": [
    "print(\"SMAPE: \", smape_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d78b2c-7574-4b0b-806c-adb5db324998",
   "metadata": {},
   "source": [
    "Oops... What about `TS2VecEmbeddingModel`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fab4711f-7b9d-4263-abbd-05a3cedcaaef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=1)]: Done   2 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=1)]: Done   3 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=1)]: Done   4 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=1)]: Done   5 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=1)]: Done   5 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=1)]: Done   1 tasks      | elapsed:   28.5s\n",
      "[Parallel(n_jobs=1)]: Done   2 tasks      | elapsed:   56.7s\n",
      "[Parallel(n_jobs=1)]: Done   3 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=1)]: Done   4 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=1)]: Done   5 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=1)]: Done   5 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=1)]: Done   1 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done   2 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done   3 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done   4 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done   5 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done   5 tasks      | elapsed:    0.4s\n"
     ]
    }
   ],
   "source": [
    "emb_model = TS2VecEmbeddingModel(\n",
    "    input_dims=1, hidden_dims=64, depth=5, output_dims=16, device=\"cuda\"\n",
    ")\n",
    "training_params = {\"n_epochs\": 20, \"lr\": 0.0005}\n",
    "smape_score = forecast_with_window_embeddings(emb_model, training_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98e0bd1b-ebd5-46da-8255-5f5a630419b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMAPE:  19.582587762579827\n"
     ]
    }
   ],
   "source": [
    "print(\"SMAPE: \", smape_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972781d8-5bb8-4194-9e73-96fbb5ebfe68",
   "metadata": {},
   "source": [
    "Window embeddings don't help with this dataset. It means that in common you should try both models and both transforms to get the best results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
